{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanaaria/Hyperparameter-Optimization/blob/main/Optimization_hyper_parameters_Esol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IODlpprwyUlW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from pandas import read_csv\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "6FZvxwP-SPel",
        "outputId": "5edbe1ec-e5c6-4b89-de87-4e535261e6a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc5ef9ce-c06f-4218-8768-4d0bbd15cce2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc5ef9ce-c06f-4218-8768-4d0bbd15cce2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Esol.csv to Esol.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        " \n",
        " \n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ebhdW5fqS7sh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        " \n",
        "data = pd.read_csv(io.BytesIO(uploaded['Esol.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HKE89aPLaN7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2660293-6acb-4d1f-a580-e1abddeb1726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MQv4GCtKcRis"
      },
      "outputs": [],
      "source": [
        "Xdata = data.iloc[:,0:200]\n",
        "Ydata = data.iloc[:,200:201]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R1VP0adqcTrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca2a30d-c866-495b-9c4e-b7797cdd92aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1128, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Ydata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zBeYZLA1cVX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba0c8a28-a436-4815-d4d4-8b4f60d933c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1128, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "Xdata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4sqBbEu-cXat"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(Xdata, Ydata, test_size=0.25, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SZHBTztdcZzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e731bdd-bb6a-4079-ea33-406877d7475a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(846, 200) (846, 1) (282, 200) (282, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# scaler_data = preprocessing.MinMaxScaler()\n",
        "# X_train = scaler_data.fit_transform(X_train)\n",
        "# X_test = scaler_data.transform(X_test)\n",
        "scaler_labels = preprocessing.MinMaxScaler()\n",
        "Y_train = scaler_labels.fit_transform(Y_train.values.reshape(-1, 1))\n",
        "Y_test = scaler_labels.transform(Y_test.values.reshape(-1, 1))\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
        "#print(X_train)\n",
        "#print(\"Train labels before scaling: {} {} {}Train labels after scaling: {} {}\".format('\\n',train_labels_before,'\\n', '\\n', train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FDjzu0XGcdcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaa03d0-da05-4587-f719-75a66628891d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s5pNf3XRcfZm"
      },
      "outputs": [],
      "source": [
        "X_train=np.array(X_train)\n",
        "X_test=np.array(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SaFjyAxdwrWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfa692f-d8e5-402d-9157-b4e187928edf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(846, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tXxljbrgchsM"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn import metrics\n",
        "# model= LinearRegression(fit_intercept=False)\n",
        "# model2=model.fit(X_train, Y_train)\n",
        "# print(model2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "feE_qeLeckdD"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA as sklearnPCA\n",
        "# sklearn_pca = sklearnPCA(n_components=15)\n",
        "# X_train_pca = sklearn_pca.fit_transform(X_train)\n",
        "# print(X_train_pca.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-JwoRG2_cmLZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wUZVoY0rcnvl"
      },
      "outputs": [],
      "source": [
        "# transform to torch tensor\n",
        "\n",
        "tensor_x = torch.tensor(X_train, dtype=torch.float).to(device) \n",
        "tensor_x2 = torch.tensor(X_test, dtype=torch.float).to(device) \n",
        "\n",
        "tensor_y = torch.tensor(Y_train, dtype=torch.float).to(device)\n",
        "tensor_y2 = torch.tensor(Y_test, dtype=torch.float).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXmgtpZzcpbM",
        "outputId": "e4679f6e-032a-4f97-e950-f0831faeca02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(tensor_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TXb77RA7crlQ"
      },
      "outputs": [],
      "source": [
        "trainset = TensorDataset(tensor_x, tensor_y) \n",
        "testset = TensorDataset(tensor_x2,tensor_y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q70hnYNLct9k"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir=None):\n",
        "    return trainset, testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1c0XqNbZcv8r"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "    import ray\n",
        "except:\n",
        "    !pip install -U ray\n",
        "    import ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q8JiSDxpcx7g"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "from torchsummary import summary\n",
        "\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ccVqHz8HoT-L"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.hidden_dim1 = int(self.config.get(\"hidden_dim1\", 100))\n",
        "        self.hidden_dim2 = int(self.config.get(\"hidden_dim2\", 100))\n",
        "        self.hidden_dim3 = int(self.config.get(\"hidden_dim3\", 100))\n",
        "\n",
        "        self.act1 = self.config.get(\"act1\", \"relu\") \n",
        "        self.act2 = self.config.get(\"act2\", \"relu\") \n",
        "        self.act3 = self.config.get(\"act3\", \"relu\")\n",
        "\n",
        "        self.linear1 = nn.Linear(200, self.hidden_dim1)\n",
        "        self.linear2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
        "        self.linear3 = nn.Linear(self.hidden_dim2, self.hidden_dim3)\n",
        "        self.linear4 = nn.Linear(self.hidden_dim3, 1)\n",
        "    \n",
        "    @staticmethod\n",
        "    def activation_func(act_str):\n",
        "        if act_str==\"tanh\":\n",
        "            return eval(\"torch.\"+act_str)\n",
        "        elif act_str==\"selu\" or act_str==\"relu\":   \n",
        "            return eval(\"torch.nn.functional.\"+act_str)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.linear1(x)\n",
        "        output = self.activation_func(self.act1)(output)\n",
        "        output = self.linear2(output)\n",
        "        output = self.activation_func(self.act2)(output)\n",
        "        output = self.linear3(output)\n",
        "        output = self.activation_func(self.act3)(output)\n",
        "        output = self.linear4(output)        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4_LpUtYWoYaG"
      },
      "outputs": [],
      "source": [
        "model = Net({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IX6YOiTuoz63"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFSQf_n4o1tP",
        "outputId": "80f59ce0-7d8a-47bf-8a99-61a19f19d09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 100]          20,100\n",
            "            Linear-2               [-1, 1, 100]          10,100\n",
            "            Linear-3               [-1, 1, 100]          10,100\n",
            "            Linear-4                 [-1, 1, 1]             101\n",
            "================================================================\n",
            "Total params: 40,401\n",
            "Trainable params: 40,401\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.15\n",
            "Estimated Total Size (MB): 0.16\n",
            "----------------------------------------------------------------\n",
            "+----------------+------------+\n",
            "|    Modules     | Parameters |\n",
            "+----------------+------------+\n",
            "| linear1.weight |   20000    |\n",
            "|  linear1.bias  |    100     |\n",
            "| linear2.weight |   10000    |\n",
            "|  linear2.bias  |    100     |\n",
            "| linear3.weight |   10000    |\n",
            "|  linear3.bias  |    100     |\n",
            "| linear4.weight |    100     |\n",
            "|  linear4.bias  |     1      |\n",
            "+----------------+------------+\n",
            "Total Trainable Params: 40401\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40401"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "summary(model, (1,tensor_x.shape[1]))\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4Ipyeowlo4UW"
      },
      "outputs": [],
      "source": [
        "def trainable_func(config, checkpoint_dir=None, data_dir=None, epochs=10):\n",
        "\n",
        "    net = Net(config)\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    '''\n",
        "    Define a loss function\n",
        "    '''\n",
        "    ## Classification\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ## Regression\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "\n",
        "    # Define an optimizer \n",
        "    optimizer = optim.Adam(net.parameters(), lr=config.get(\"lr\",0.0003))\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    # Load data\n",
        "    trainset, testset = load_data(data_dir)\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    train_size = int(len(trainset) * 0.66)\n",
        "    train_subset, val_subset = random_split(trainset, [train_size, len(trainset) - train_size])\n",
        "\n",
        "    # Define data loaders (which combines a dataset and a sampler, and provides an iterable over the given dataset)\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config.get(\"batch_size\",32)),\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config.get(\"batch_size\",32)),\n",
        "        shuffle=True,\n",
        "        num_workers=2)\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "        epoch_train_loss = 0.0\n",
        "        # epoch_steps = 0\n",
        "        net.train() # Prepare model for training\n",
        "        for i, data in enumerate(trainloader):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            '''\n",
        "            Compute train loss without scaling to print\n",
        "            ''' \n",
        "            # outputs = torch.tensor(scaler_labels.inverse_transform(outputs.detach().cpu())).to(device)    \n",
        "            # labels = torch.tensor(scaler_labels.inverse_transform(labels.cpu())).to(device)  \n",
        "            # loss_train = criterion(outputs, labels) \n",
        "            # epoch_train_loss += loss_train.detach().item()\n",
        "        # print(\"[%d] loss: %.3f\" % (epoch + 1, epoch_train_loss / len(train_subset)))\n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        net.eval() # Prepare model for evaluation\n",
        "        for i, data in enumerate(valloader):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "\n",
        "                # Inverse transform of the labels' scaler\n",
        "                outputs = torch.tensor(scaler_labels.inverse_transform(outputs.detach().cpu())).to(device)    \n",
        "                labels = torch.tensor(scaler_labels.inverse_transform(labels.cpu())).to(device) \n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(epoch = epoch, loss=(val_loss / len(val_subset)))\n",
        "    print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DL9giDwao9Bk"
      },
      "outputs": [],
      "source": [
        "def test_score(config, net, device=\"cpu\"):\n",
        "    trainset, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=int(config.get(\"batch_size\",32)), shuffle=False, num_workers=2)\n",
        "    \n",
        "    ## Regression\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "\n",
        "    # Test loss\n",
        "    test_loss = 0.0\n",
        "    net.eval() # Prepare model for evaluation\n",
        "    for i, data in enumerate(testloader):\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # Inverse transform of the labels' scaler\n",
        "            outputs = torch.tensor(scaler_labels.inverse_transform(outputs.detach().cpu())).to(device)    \n",
        "            labels = torch.tensor(scaler_labels.inverse_transform(labels.cpu())).to(device) \n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.cpu().numpy()\n",
        "\n",
        "    return test_loss / len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gI9cqZQHo_lT",
        "outputId": "06e5998c-5db3-4d98-c307-b45ea13dbb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CPU': 2.0, 'object_store_memory': 3940834099.0, 'node:172.28.0.2': 1.0, 'memory': 7881668199.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "ray.shutdown()\n",
        "ray.init() # Here we use ray.init() to evaluate available_resources for Ray\n",
        "print(ray.available_resources())\n",
        "#ray.shutdown()  # Restart Ray defensively in case the ray connection is lost. \n",
        "\n",
        "# # Start Ray runtime with specific resources (not nessesarily all resources)\n",
        "# # You can change this values based on your machine resources)\n",
        "# ray.init(num_cpus=2, num_gpus=0) \n",
        "# print(ray.available_resources())\n",
        "# \"\"\"Check Ray Tune is working properly (for trainable class)\"\"\"\n",
        "# # from ray.tune.utils import validate_save_restore\n",
        "# # validate_save_restore(Trainable)\n",
        "# # validate_save_restore(Trainable, use_object_store=True)\n",
        "# # print(\"Success!\")\n",
        "\"\"\"\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "osC7wp3WpEBh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "    import optuna\n",
        "except:\n",
        "    %pip install optuna\n",
        "    import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install hpbandster ConfigSpace"
      ],
      "metadata": {
        "id": "RUZbWGLFJG3y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lQNGlLq0AxYV"
      },
      "outputs": [],
      "source": [
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.suggest.optuna import OptunaSearch  \n",
        "from ray.tune.suggest.dragonfly import DragonflySearch\n",
        "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
        "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.schedulers import MedianStoppingRule\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "from ray.tune.suggest.bohb import TuneBOHB\n",
        "from ray.tune.suggest.basic_variant import BasicVariantGenerator\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oFMVUl2ZpHL5",
        "outputId": "0b9112b9-0ad3-4ecd-c718-b0c21da5d661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-18 13:14:34,467\tINFO logger.py:630 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2022-07-18 13:14:34,469\tWARNING callback.py:106 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:14:38 (running for 00:00:04.21)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 0.5/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 1/10 (1 RUNNING)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_91423c50 reported epoch=0,loss=17.440669458060825,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'selu', 'lr': 0.0009, 'batch_size': 128, 'hidden_dim1': 90.0, 'hidden_dim2': 140.0, 'hidden_dim3': 150.0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:14:52 (running for 00:00:18.00)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 5/10 (1 PENDING, 4 RUNNING)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_93c11ad2 reported epoch=0,loss=3.064851825050516,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 16, 'hidden_dim1': 140.0, 'hidden_dim2': 120.0, 'hidden_dim3': 110.0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:14:52 (running for 00:00:18.04)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: None | Iter 4.000: None\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 5/10 (1 PENDING, 4 RUNNING)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_93cb54a2 reported epoch=0,loss=16.118519994738662,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'selu', 'lr': 0.0009, 'batch_size': 64, 'hidden_dim1': 130.0, 'hidden_dim2': 120.0, 'hidden_dim3': 80.0}.\n",
            "Trial trainable_func_91423c50 reported epoch=3,loss=2.6038107909149684,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'selu', 'lr': 0.0009, 'batch_size': 128, 'hidden_dim1': 90.0, 'hidden_dim2': 140.0, 'hidden_dim3': 150.0}.\n",
            "Trial trainable_func_93d933f6 reported epoch=0,loss=1.0389868067899235,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 130.0, 'hidden_dim2': 90.0, 'hidden_dim3': 120.0}.\n",
            "Trial trainable_func_91423c50 reported epoch=9,loss=1.1381669272589074,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'selu', 'lr': 0.0009, 'batch_size': 128, 'hidden_dim1': 90.0, 'hidden_dim2': 140.0, 'hidden_dim3': 150.0}. This trial completed.\n",
            "Trial trainable_func_93ebf496 reported epoch=0,loss=7.8888866383328455,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 110.0, 'hidden_dim2': 170.0, 'hidden_dim3': 190.0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:14:57 (running for 00:00:23.17)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: -1.393456426977676 | Iter 4.000: -2.403283973803938\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 6/10 (1 PENDING, 4 RUNNING, 1 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_93cb54a2 reported epoch=9,loss=0.7849207953502383,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'selu', 'lr': 0.0009, 'batch_size': 64, 'hidden_dim1': 130.0, 'hidden_dim2': 120.0, 'hidden_dim3': 80.0}. This trial completed.\n",
            "Trial trainable_func_93c11ad2 reported epoch=4,loss=0.6936714567252604,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 16, 'hidden_dim1': 140.0, 'hidden_dim2': 120.0, 'hidden_dim3': 110.0}.\n",
            "Trial trainable_func_9e38c7f8 reported epoch=0,loss=12.844334359492905,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 140.0, 'hidden_dim2': 90.0, 'hidden_dim3': 190.0}.\n",
            "Trial trainable_func_93d933f6 reported epoch=2,loss=0.5999428702235664,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 130.0, 'hidden_dim2': 90.0, 'hidden_dim3': 120.0}.\n",
            "Trial trainable_func_93ebf496 reported epoch=7,loss=0.7412636989449557,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 110.0, 'hidden_dim2': 170.0, 'hidden_dim3': 190.0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:15:03 (running for 00:00:28.57)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 8.000: -0.8667040459309158 | Iter 4.000: -1.9434348544729554\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 7/10 (1 PENDING, 4 RUNNING, 2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_93ebf496 reported epoch=9,loss=0.6003775786979485,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'selu', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 110.0, 'hidden_dim2': 170.0, 'hidden_dim3': 190.0}. This trial completed.\n",
            "Trial trainable_func_9e38c7f8 reported epoch=7,loss=0.7705942938062129,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 140.0, 'hidden_dim2': 90.0, 'hidden_dim3': 190.0}.\n",
            "Trial trainable_func_93c11ad2 reported epoch=8,loss=0.5208770681430087,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 16, 'hidden_dim1': 140.0, 'hidden_dim2': 120.0, 'hidden_dim3': 110.0}.\n",
            "Trial trainable_func_9e38c7f8 reported epoch=9,loss=0.6379632229326037,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'relu', 'lr': 0.001, 'batch_size': 64, 'hidden_dim1': 140.0, 'hidden_dim2': 90.0, 'hidden_dim3': 190.0}. This trial completed.\n",
            "Trial trainable_func_9f49aaa4 reported epoch=0,loss=1.618199341451365,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.0008, 'batch_size': 16, 'hidden_dim1': 130.0, 'hidden_dim2': 100.0, 'hidden_dim3': 50.0}.\n",
            "Trial trainable_func_93d933f6 reported epoch=4,loss=0.5932059686277451,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 130.0, 'hidden_dim2': 90.0, 'hidden_dim3': 120.0}.\n",
            "Trial trainable_func_a2b37814 reported epoch=0,loss=24.41551914164358,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'relu', 'lr': 0.001, 'batch_size': 128, 'hidden_dim1': 60.0, 'hidden_dim2': 110.0, 'hidden_dim3': 60.0}.\n",
            "Trial trainable_func_93c11ad2 reported epoch=9,loss=0.5300298193447603,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 16, 'hidden_dim1': 140.0, 'hidden_dim2': 120.0, 'hidden_dim3': 110.0}. This trial completed.\n",
            "Trial trainable_func_a392d8ba reported epoch=0,loss=12.50361952390098,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 64, 'hidden_dim1': 180.0, 'hidden_dim2': 170.0, 'hidden_dim3': 190.0}.\n",
            "Trial trainable_func_a2b37814 reported epoch=3,loss=5.729707334451324,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'relu', 'lr': 0.001, 'batch_size': 128, 'hidden_dim1': 60.0, 'hidden_dim2': 110.0, 'hidden_dim3': 60.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:15:08 (running for 00:00:33.80)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=1\n",
              "Bracket: Iter 8.000: -0.7705942938062129 | Iter 4.000: -2.1733594141384467\n",
              "Bracket: Iter 8.000: None\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 10/10 (4 RUNNING, 6 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_a392d8ba reported epoch=3,loss=2.2843612670953815,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'relu', 'act3': 'tanh', 'lr': 0.0006000000000000001, 'batch_size': 64, 'hidden_dim1': 180.0, 'hidden_dim2': 170.0, 'hidden_dim3': 190.0}. This trial completed.\n",
            "Trial trainable_func_a41a6140 reported epoch=0,loss=1.2045159428622336,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'tanh', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 50.0, 'hidden_dim2': 50.0, 'hidden_dim3': 160.0}.\n",
            "Trial trainable_func_93d933f6 reported epoch=6,loss=0.8236056340690848,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 130.0, 'hidden_dim2': 90.0, 'hidden_dim3': 120.0}.\n",
            "Trial trainable_func_9f49aaa4 reported epoch=4,loss=0.47884687595026787,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.0008, 'batch_size': 16, 'hidden_dim1': 130.0, 'hidden_dim2': 100.0, 'hidden_dim3': 50.0}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:15:13 (running for 00:00:38.86)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=2\n",
              "Bracket: Iter 8.000: -0.7705942938062129 | Iter 4.000: -2.2843612670953815\n",
              "Bracket: Iter 8.000: -0.49561344418448194\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 1.5/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_a41a6140 reported epoch=3,loss=0.5706146101006461,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'tanh', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 50.0, 'hidden_dim2': 50.0, 'hidden_dim3': 160.0}.\n",
            "Trial trainable_func_93d933f6 reported epoch=9,loss=0.5068161353914244,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 130.0, 'hidden_dim2': 90.0, 'hidden_dim3': 120.0}. This trial completed.\n",
            "Trial trainable_func_9f49aaa4 reported epoch=9,loss=0.40030034507859646,should_checkpoint=True with parameters={'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.0008, 'batch_size': 16, 'hidden_dim1': 130.0, 'hidden_dim2': 100.0, 'hidden_dim3': 50.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:15:18 (running for 00:00:43.98)<br>Memory usage on this node: 1.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=2\n",
              "Bracket: Iter 8.000: -0.7705942938062129 | Iter 4.000: -2.2843612670953815\n",
              "Bracket: Iter 8.000: -0.49561344418448194\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 0.5/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial trainable_func_a41a6140 reported epoch=8,loss=0.4495451084063111,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'tanh', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 50.0, 'hidden_dim2': 50.0, 'hidden_dim3': 160.0}.\n",
            "Trial trainable_func_a41a6140 reported epoch=9,loss=0.4789958897674212,should_checkpoint=True with parameters={'act1 ': 'selu', 'act2': 'tanh', 'act3': 'tanh', 'lr': 0.001, 'batch_size': 8, 'hidden_dim1': 50.0, 'hidden_dim2': 50.0, 'hidden_dim3': 160.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-07-18 13:15:21 (running for 00:00:46.81)<br>Memory usage on this node: 1.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=2\n",
              "Bracket: Iter 8.000: -0.7705942938062129 | Iter 4.000: -2.2843612670953815\n",
              "Bracket: Iter 8.000: -0.46689831112446856\n",
              "Bracket: \n",
              "Bracket: \n",
              "Bracket: <br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects<br>Result logdir: /root/ray_results/trainable_func_2022-07-18_13-14-34<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th>act1   </th><th>act2  </th><th>act3  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  hidden_dim1</th><th style=\"text-align: right;\">  hidden_dim2</th><th style=\"text-align: right;\">  hidden_dim3</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">    loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>trainable_func_91423c50</td><td>TERMINATED</td><td>172.28.0.2:418</td><td>tanh   </td><td>selu  </td><td>selu  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           90</td><td style=\"text-align: right;\">          140</td><td style=\"text-align: right;\">          150</td><td style=\"text-align: right;\">0.0009</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        17.5287 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">1.13817 </td></tr>\n",
              "<tr><td>trainable_func_93c11ad2</td><td>TERMINATED</td><td>172.28.0.2:461</td><td>tanh   </td><td>relu  </td><td>tanh  </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          140</td><td style=\"text-align: right;\">          120</td><td style=\"text-align: right;\">          110</td><td style=\"text-align: right;\">0.0006</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        16.7247 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.53003 </td></tr>\n",
              "<tr><td>trainable_func_93cb54a2</td><td>TERMINATED</td><td>172.28.0.2:468</td><td>tanh   </td><td>relu  </td><td>selu  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          130</td><td style=\"text-align: right;\">          120</td><td style=\"text-align: right;\">           80</td><td style=\"text-align: right;\">0.0009</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.67965</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.784921</td></tr>\n",
              "<tr><td>trainable_func_93d933f6</td><td>TERMINATED</td><td>172.28.0.2:552</td><td>selu   </td><td>tanh  </td><td>selu  </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          130</td><td style=\"text-align: right;\">           90</td><td style=\"text-align: right;\">          120</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        23.8237 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.506816</td></tr>\n",
              "<tr><td>trainable_func_93ebf496</td><td>TERMINATED</td><td>172.28.0.2:418</td><td>tanh   </td><td>selu  </td><td>relu  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          110</td><td style=\"text-align: right;\">          170</td><td style=\"text-align: right;\">          190</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.48609</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.600378</td></tr>\n",
              "<tr><td>trainable_func_9e38c7f8</td><td>TERMINATED</td><td>172.28.0.2:468</td><td>tanh   </td><td>tanh  </td><td>relu  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          140</td><td style=\"text-align: right;\">           90</td><td style=\"text-align: right;\">          190</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.16967</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.637963</td></tr>\n",
              "<tr><td>trainable_func_9f49aaa4</td><td>TERMINATED</td><td>172.28.0.2:418</td><td>tanh   </td><td>tanh  </td><td>selu  </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">          130</td><td style=\"text-align: right;\">          100</td><td style=\"text-align: right;\">           50</td><td style=\"text-align: right;\">0.0008</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        12.6571 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.4003  </td></tr>\n",
              "<tr><td>trainable_func_a2b37814</td><td>TERMINATED</td><td>172.28.0.2:468</td><td>selu   </td><td>tanh  </td><td>relu  </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           60</td><td style=\"text-align: right;\">          110</td><td style=\"text-align: right;\">           60</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2.07764</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">5.72971 </td></tr>\n",
              "<tr><td>trainable_func_a392d8ba</td><td>TERMINATED</td><td>172.28.0.2:461</td><td>selu   </td><td>relu  </td><td>tanh  </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          180</td><td style=\"text-align: right;\">          170</td><td style=\"text-align: right;\">          190</td><td style=\"text-align: right;\">0.0006</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         3.04787</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">2.28436 </td></tr>\n",
              "<tr><td>trainable_func_a41a6140</td><td>TERMINATED</td><td>172.28.0.2:468</td><td>selu   </td><td>tanh  </td><td>tanh  </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">           50</td><td style=\"text-align: right;\">           50</td><td style=\"text-align: right;\">          160</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        13.8574 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.478996</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-18 13:15:21,518\tINFO tune.py:748 -- Total run time: 47.08 seconds (46.75 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial config: {'act1 ': 'tanh', 'act2': 'tanh', 'act3': 'selu', 'lr': 0.0008, 'batch_size': 16, 'hidden_dim1': 130.0, 'hidden_dim2': 100.0, 'hidden_dim3': 50.0}\n",
            "Best trial final validation score: 0.40030034507859646\n",
            "Best trial test set score: 0.42016356573246605\n"
          ]
        }
      ],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
        "\n",
        "    # define data directory here if you want to load data from files\n",
        "    data_dir = os.path.abspath(\"./Esol\")\n",
        "    load_data()\n",
        "\n",
        "    # define the search space of hyperparameters\n",
        "    config = {\n",
        "        \"act1 \": tune.choice([\"relu\",\"tanh\",\"selu\"]),\n",
        "        \"act2\" : tune.choice([\"relu\",\"tanh\",\"selu\"]),\n",
        "        \"act3\" : tune.choice([\"relu\",\"tanh\",\"selu\"]),\n",
        "        \"lr\": tune.quniform(0.0005, 0.001, 0.0001),\n",
        "        \"batch_size\": tune.choice([8, 16, 32 ,64,128]),\n",
        "        \"hidden_dim1\" : tune.quniform(50, 200, 10),\n",
        "        \"hidden_dim2\" : tune.quniform(50, 200, 10),\n",
        "        \"hidden_dim3\" : tune.quniform(50, 200, 10),\n",
        "    }\n",
        "\n",
        "    # Optuna search algorithm\n",
        "    from ray.tune.suggest.optuna import OptunaSearch \n",
        "    from ray.tune.suggest import ConcurrencyLimiter\n",
        "    search_alg = OptunaSearch(\n",
        "        metric=\"loss\", #or accuracy, etc.\n",
        "        mode=\"min\", #or max\n",
        "        # seed = 42,\n",
        "        # points_to_evaluate=[\n",
        "        # {'lr': 0.0005, 'hidden_size': 150.0, 'readout1_out': 200.0, 'readout2_out': 180.0}\n",
        "        # ],\n",
        "        )\n",
        "    \n",
        "    search_alg = ConcurrencyLimiter(search_alg, max_concurrent=10)\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric =\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        reduction_factor=2, \n",
        "        grace_period=4,\n",
        "        brackets=5\n",
        "        )\n",
        "    \n",
        "   \n",
        "    # wrap data loading and training for tuning using `partial` \n",
        "    # (note that there exist other methods for this purpose)\n",
        "    result = tune.run(\n",
        "        partial(trainable_func, data_dir=data_dir, epochs=max_num_epochs),\n",
        "        scheduler=scheduler,\n",
        "        search_alg=search_alg,\n",
        "        num_samples=num_samples,\n",
        "        config=config,\n",
        "        verbose=2,\n",
        "        checkpoint_score_attr=\"loss\",\n",
        "        checkpoint_freq=0,\n",
        "        keep_checkpoints_num=1,\n",
        "        # checkpoint_at_end=True,\n",
        "        # reuse_actors=reuse_actors_status,\n",
        "        #progress_reporter=reporter,\n",
        "        resources_per_trial={\"cpu\": 0.5, \"gpu\": gpus_per_trial},\n",
        "        stop={\"training_iteration\": max_num_epochs},                \n",
        "        )\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation score: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "\n",
        "    best_trained_model = Net(best_trial.config)\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_score_value = test_score(best_trial.config, best_trained_model, device)\n",
        "    print(\"Best trial test set score: {}\".format(test_score_value))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # You can change the number of GPUs per trial here:\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfFf8e_ta5qH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-thYQk6c2U5"
      },
      "outputs": [],
      "source": [
        "# !pip install -U hyperopt\n",
        "# !pip install hpbandster ConfigSpace\n",
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na9ImKcRpKaV"
      },
      "outputs": [],
      "source": [
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.suggest.optuna import OptunaSearch  \n",
        "from ray.tune.suggest.dragonfly import DragonflySearch\n",
        "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
        "from ray.tune.schedulers.hb_bohb import HyperBandForBOHB\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.schedulers import MedianStoppingRule\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "from ray.tune.suggest.bohb import TuneBOHB\n",
        "from ray.tune.suggest.basic_variant import BasicVariantGenerator\n",
        "from ray.tune.suggest import ConcurrencyLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTFMuWRzpOHa"
      },
      "outputs": [],
      "source": [
        "training_iteration = 50 #max_num_epochs\n",
        "\n",
        "## ASHA\n",
        "scheduler = AsyncHyperBandScheduler(\n",
        "    time_attr=\"training_iteration\",\n",
        "    max_t=training_iteration,\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    reduction_factor=2, \n",
        "    grace_period=4,\n",
        "    brackets=5,\n",
        "    )\n",
        "\n",
        "## BOHB\n",
        "scheduler = HyperBandForBOHB(\n",
        "    time_attr=\"training_iteration\",\n",
        "    max_t=training_iteration, \n",
        "    reduction_factor=8, \n",
        "    stop_last_trials=True,\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    )\n",
        "\n",
        "## Median\n",
        "scheduler = MedianStoppingRule(\n",
        "    time_attr=\"training_iteration\",\n",
        "    grace_period=10,\n",
        "    min_samples_required=10,\n",
        "    hard_stop = True,\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    )\n",
        "\n",
        "## PBT\n",
        "scheduler = PopulationBasedTraining(\n",
        "    time_attr=\"training_iteration\",\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    perturbation_interval=10,  # every 10 `time_attr` units\n",
        "                            # (training_iterations in this case)\n",
        "    # hyperparam_mutations={\n",
        "    #     \"lr\": [8e-3, 7e-3, 6e-3, 5e-3, 4e-3],\n",
        "    #     \"dropout\": tune.quniform(0.0, 0.4, 0.05),\n",
        "    #     \"dropout1\": tune.quniform(0.0, 0.4, 0.05),\n",
        "    #     \"dropout2\": tune.quniform(0.0, 0.4, 0.05),\n",
        "    #     \"max_norm_val\":tune.choice([2.5, 3, 3.5, 4]),\n",
        "    #     }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTEOu4x_1di3"
      },
      "outputs": [],
      "source": [
        "# !pip install Cython\n",
        "# !pip install ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF5VUaj-Woz-"
      },
      "outputs": [],
      "source": [
        "# !pip install hpbandster ConfigSpace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3BVwwJ3WMlw",
        "outputId": "982a21c3-f75a-481f-af44-5305fee13a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dragonfly-opt in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dragonfly-opt) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dragonfly-opt) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from dragonfly-opt) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from dragonfly-opt) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dragonfly-opt\n",
        "import dragonfly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFxAXYDNWtM2"
      },
      "outputs": [],
      "source": [
        "from ray.tune.suggest.dragonfly import DragonflySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pypfAW1pW4u_"
      },
      "outputs": [],
      "source": [
        "import dragonfly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zFCU4ZRl9qZ"
      },
      "outputs": [],
      "source": [
        "## BOHB\n",
        "search_alg = TuneBOHB(\n",
        "    # space=config_space,  # If you want to set the space manually\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    # seed = 42,\n",
        "    # points_to_evaluate=[\n",
        "    # ],\n",
        "    )\n",
        "\n",
        "## Hyperopt\n",
        "search_alg = HyperOptSearch(\n",
        "    # space=config,\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    n_initial_points=60,\n",
        "    # gamma = 0.1,\n",
        "    # random_state_seed=42,\n",
        "    # points_to_evaluate=[{\"max_norm_val\": 2.5, 'GNN_Layers': 3, 'dropout': 0.25, 'dropout1': 0.35, 'dropout2': 0.15, 'lr': 0.001, 'hidden_size': 80, 'readout1_out': 150, 'readout2_out': 100, 'batch_size': 64}],\n",
        "    )\n",
        "\n",
        "## Optuna\n",
        "search_alg = OptunaSearch(\n",
        "    metric=\"loss\", #or accuracy, etc.\n",
        "    mode=\"min\", #or max\n",
        "    # seed = 42,\n",
        "    # points_to_evaluate=[\n",
        "    # {'dropout': 0.2, 'dropout1': 0.1, 'dropout2': 0.25, 'lr': 0.0005, 'hidden_size': 150.0, 'readout1_out': 200.0, 'readout2_out': 180.0, 'max_norm_val': 2.5}\n",
        "    # ],\n",
        "    )\n",
        "\n",
        "# ## Dragonfly\n",
        "# search_alg = DragonflySearch(\n",
        "#     metric=\"loss\", #or accuracy, etc.\n",
        "#     mode=\"min\", #or max\n",
        "#     optimizer=\"bandit\", #[random, bandit, genetic]\n",
        "#     # points_to_evaluate=[\n",
        "#     # {'max_norm_val': 2.5, 'dropout': 0.3, 'dropout1': 0.1, 'dropout2': 0.0, 'lr': 0.0008, 'hidden_size': 90, 'readout1_out': 150, 'readout2_out': 140}\n",
        "#     # ],\n",
        "#     # domain=euclidean, #[cartesian, euclidean]\n",
        "#     )\n",
        "\n",
        "# ## Bayesopt\n",
        "# search_alg = BayesOptSearch(\n",
        "#     metric=\"loss\", #or accuracy, etc.\n",
        "#     mode=\"min\", #or max\n",
        "#     random_search_steps = 60, \n",
        "#     # points_to_evaluate=[\n",
        "#     # {'max_norm_val': 2.5, 'dropout': 0.3, 'dropout1': 0.1, 'dropout2': 0.0, 'lr': 0.0008, 'hidden_size': 90, 'readout1_out': 150, 'readout2_out': 140}\n",
        "#     # ],\n",
        "#     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-JdPltQSdt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Optimization hyper parameters Esol",
      "provenance": [],
      "authorship_tag": "ABX9TyM2cPGaTVw7yvhsYyNZwy7r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}